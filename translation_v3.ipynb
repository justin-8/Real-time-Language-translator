{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab25ae-6599-4955-912a-b87cc777f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import pytesseract\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sacrebleu import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8286f-bbf1-4f6d-b9c8-63de93156184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SubtitleDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_texts, tgt_texts = zip(*batch)\n",
    "    return list(src_texts), list(tgt_texts)\n",
    "\n",
    "class VideoSubtitleTranslator:\n",
    "    def __init__(self, src_lang='de', tgt_lang='en', model_path=None):\n",
    "        self.src_lang = src_lang\n",
    "        self.tgt_lang = tgt_lang\n",
    "        self.fps = 30.0\n",
    "        self.sync_threshold = 0.02  # 2% of a frame duration for 98% accuracy\n",
    "        \n",
    "        # Load pre-trained translation model\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            self.model = torch.load(model_path)\n",
    "        else:\n",
    "            model_name = f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}'\n",
    "            self.model = MarianMTModel.from_pretrained(model_name)\n",
    "        \n",
    "        self.tokenizer = MarianTokenizer.from_pretrained(f'Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}')\n",
    "        \n",
    "        # Set device (use GPU if available)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def preprocess_video(self, video_path):\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / self.fps\n",
    "        \n",
    "        frames = []\n",
    "        timestamps = []\n",
    "        \n",
    "        for i in tqdm(range(total_frames), desc=\"Extracting frames\"):\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame)\n",
    "            timestamps.append(i / self.fps)\n",
    "        \n",
    "        video.release()\n",
    "        return frames, timestamps\n",
    "\n",
    "    def extract_text_from_frame(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        text = pytesseract.image_to_string(thresh, lang=self.src_lang)\n",
    "        return text.strip()\n",
    "\n",
    "    def translate_text(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            translated = self.model.generate(**inputs)\n",
    "        \n",
    "        return self.tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "    def process_frame(self, frame, timestamp):\n",
    "        text = self.extract_text_from_frame(frame)\n",
    "        if text:\n",
    "            translated_text = self.translate_text(text)\n",
    "            return Subtitle(translated_text, timestamp, timestamp + 1.0 / self.fps)\n",
    "        return None\n",
    "\n",
    "    def translate_video(self, video_path):\n",
    "        frames, timestamps = self.preprocess_video(video_path)\n",
    "        subtitles = []\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(self.process_frame, frame, timestamp) \n",
    "                       for frame, timestamp in zip(frames, timestamps)]\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                subtitle = future.result()\n",
    "                if subtitle:\n",
    "                    subtitles.append(subtitle)\n",
    "        \n",
    "        return self.post_process_subtitles(subtitles)\n",
    "\n",
    "    def post_process_subtitles(self, subtitles):\n",
    "        subtitles.sort(key=lambda x: x.start_time)\n",
    "        \n",
    "        processed_subtitles = []\n",
    "        current_subtitle = None\n",
    "        \n",
    "        for subtitle in subtitles:\n",
    "            if current_subtitle is None:\n",
    "                current_subtitle = subtitle\n",
    "            elif subtitle.start_time - current_subtitle.end_time <= self.sync_threshold:\n",
    "                current_subtitle.text += \" \" + subtitle.text\n",
    "                current_subtitle.end_time = subtitle.end_time\n",
    "            else:\n",
    "                processed_subtitles.append(current_subtitle)\n",
    "                current_subtitle = subtitle\n",
    "        \n",
    "        if current_subtitle:\n",
    "            processed_subtitles.append(current_subtitle)\n",
    "        \n",
    "        return processed_subtitles\n",
    "\n",
    "    def export_subtitles(self, subtitles, output_path):\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            for i, subtitle in enumerate(subtitles, 1):\n",
    "                f.write(f\"{i}\\n\")\n",
    "                f.write(f\"{self.format_time(subtitle.start_time)} --> {self.format_time(subtitle.end_time)}\\n\")\n",
    "                f.write(f\"{subtitle.text}\\n\\n\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c99913-6a3b-481a-b518-4957e653461d",
   "metadata": {},
   "outputs": [],
   "source": [
    " @staticmethod\n",
    "    def format_time(seconds):\n",
    "        hours = int(seconds / 3600)\n",
    "        minutes = int((seconds % 3600) / 60)\n",
    "        seconds = seconds % 60\n",
    "        milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "        return f\"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}\"\n",
    "\n",
    "    def train(self, train_data, val_data, epochs=5, batch_size=32):\n",
    "        train_dataset = SubtitleDataset(train_data)\n",
    "        val_dataset = SubtitleDataset(val_data)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0\n",
    "            \n",
    "            for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "                src_texts, tgt_texts = batch\n",
    "                \n",
    "                inputs = self.tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                inputs = inputs.to(self.device)\n",
    "                \n",
    "                targets = self.tokenizer(tgt_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                target_ids = targets['input_ids'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(**inputs, labels=target_ids)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "            \n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            val_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    src_texts, tgt_texts = batch\n",
    "                    inputs = self.tokenizer(src_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = self.tokenizer(tgt_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                    target_ids = targets['input_ids'].to(self.device)\n",
    "                    outputs = self.model(**inputs, labels=target_ids)\n",
    "                    val_loss += outputs.loss.item()\n",
    "            \n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        self.model.eval()\n",
    "        hypotheses = []\n",
    "        references = []\n",
    "        \n",
    "        for src_text, tgt_text in tqdm(test_data, desc=\"Evaluating\"):\n",
    "            inputs = self.tokenizer(src_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "            inputs = inputs.to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                translated = self.model.generate(**inputs)\n",
    "            \n",
    "            translated_text = self.tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "            hypotheses.append(translated_text)\n",
    "            references.append([tgt_text])\n",
    "        \n",
    "        bleu_score = corpus_bleu(hypotheses, references)\n",
    "        return bleu_score.score\n",
    "\n",
    "class Subtitle:\n",
    "    def __init__(self, text, start_time, end_time):\n",
    "        self.text = text\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "\n",
    "def load_parallel_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return [(item['source'], item['target']) for item in data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f729e-bfc0-4795-b2c3-9d45e196706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    data = load_parallel_data('parallel_corpus.json')\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n",
    "\n",
    "    # Initialize translator\n",
    "    translator = VideoSubtitleTranslator(src_lang='de', tgt_lang='en')\n",
    "\n",
    "    # Train the model\n",
    "    translator.train(train_data, val_data, epochs=5, batch_size=32)\n",
    "\n",
    "    # Evaluate the model\n",
    "    bleu_score = translator.evaluate(test_data)\n",
    "    print(f\"BLEU Score: {bleu_score:.2f}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    torch.save(translator.model, 'trained_translator_model.pth')\n",
    "\n",
    "    # Translate a video\n",
    "    video_path = \"path/to/your/video.mp4\"\n",
    "    translated_subtitles = translator.translate_video(video_path)\n",
    "    translator.export_subtitles(translated_subtitles, \"translated_subtitles.srt\")\n",
    "\n",
    "    print(\"Video translation complete. Subtitles saved to 'translated_subtitles.srt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9702818-7843-48cb-be02-b73f154b4c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfba5e-cf66-4e4f-a662-3f803ce5351d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc07320d-42b2-4034-9cdf-a1968e7f7b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368eed7a-af46-4ab0-b93d-30a2e787ad47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82145051-0035-4fdc-a0a6-f0a0a194dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c9a4e-5668-4f40-bd16-b1556f87f937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43f22e-fc88-46c2-b1ba-83cd49fac1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de7eba-9ef5-4839-be34-4073bd9e9325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1d66f-cbf6-4d5e-b3c2-7aed7c152494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9267a4a-0cdd-4d67-ac38-b804a463fbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fc9cff-9d6a-4e88-bf89-2a4b422090c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5e281-9a1f-499a-bcbf-563e12d36299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06218244-cae3-4eec-bbbc-e7a20f9a1cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
